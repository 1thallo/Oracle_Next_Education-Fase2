{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810a9c4f",
   "metadata": {},
   "source": [
    "Em português a mensagem quer dizer UnicodeDecodeError: o codec 'utf-8' não pode decodificar o byte 0xe7 na posição 18: byte de continuação inválido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d2ae6",
   "metadata": {},
   "source": [
    "### Mas o que isso quer dizer? O que é esse tal de UTF-8?\n",
    "\n",
    "O erro de encoding ocorre quando a biblioteca Pandas não consegue interpretar corretamente os caracteres de um arquivo CSV. Isso pode acontecer quando ele contém caracteres especiais que não são reconhecidos pela biblioteca Pandas ou quando foi salvo em um formato de codificação diferente do esperado.\n",
    "\n",
    "Para resolver esse erro, é necessário identificar a codificação correta do arquivo CSV e especificá-la ao carregar o arquivo com a biblioteca Pandas. Essa codificação padrão é o UTF-8, mas em alguns casos, o arquivo pode ter sido salvo com uma codificação diferente, como ISO-8859-1.\n",
    "\n",
    "O UTF-8 é uma codificação de caracteres universal usada para representar caracteres de diferentes idiomas de forma compatível com a internet e com sistemas de computador em geral. A sigla UTF significa Unicode Transformation Format (Formato de Transformação Unicode) e o número 8 indica que essa codificação associa uma sequência de 1 a 4 bytes (8 a 32 bits) com cada caractere.\n",
    "\n",
    "A codificação UTF-8 é amplamente utilizada na internet e em sistemas de computador em todo o mundo, pois permite a representação de caracteres de diferentes idiomas em um único conjunto de caracteres. Além disso, essa codificação é capaz de preservar a compatibilidade com outras mais antigas, como ASCII, o que a torna uma escolha popular para a criação e compartilhamento de arquivos de texto.\n",
    "\n",
    "Pode ser que você esteja pensando neste momento: como será que a Giovanna conseguiu descobrir qual é a codificação do arquivo que ela está tentando ler?\n",
    "\n",
    "Existem algumas formas para descobrir isso, no entanto, teremos a oportunidade de experimentar uma maneira prática de fazer isso no próprio Google Colab. Vamos lá?\n",
    "\n",
    "Nós podemos usar uma biblioteca chamada chardet para detectar o encoding de um arquivo CSV. Para utilizar essa biblioteca no Google Colab, basta realizar sua importação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6542e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c58995",
   "metadata": {},
   "source": [
    "- Em seguida, digitamos o seguinte bloco de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656ae5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "with open('clientes_mercado.csv', 'rb') as file:\n",
    "    print(chardet.detect(file.read()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
